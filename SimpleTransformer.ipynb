{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arsmUpAUM5WW",
        "outputId": "50401bec-c4b7-415d-e378-e57f397a9cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 32, 10000])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers)\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.embedding(src)\n",
        "        tgt = self.embedding(tgt)\n",
        "\n",
        "        output = self.transformer(src, tgt)\n",
        "\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Example usage:\n",
        "vocab_size = 10000  # Replace with the actual size of your vocabulary\n",
        "d_model = 512\n",
        "nhead = 8\n",
        "num_encoder_layers = 6\n",
        "num_decoder_layers = 6\n",
        "\n",
        "model = Transformer(vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers)\n",
        "\n",
        "# Example input tensors (replace with your actual data)\n",
        "src = torch.randint(0, vocab_size, (10, 32))  # (sequence_length, batch_size)\n",
        "tgt = torch.randint(0, vocab_size, (20, 32))  # (sequence_length, batch_size)\n",
        "\n",
        "output = model(src, tgt)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zvCKzEfrT-n5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}